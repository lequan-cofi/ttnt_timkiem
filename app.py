import streamlit as st
import pandas as pd
import numpy as np
import json
import re
import sys
import subprocess
from urllib.parse import urlparse, quote, unquote
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
# from streamlit_extras.app_logo import app_logo
# --- C·∫§U H√åNH TRANG V√Ä CSS ---

st.set_page_config(page_title="T·∫°p ch√≠ c·ªßa b·∫°n", page_icon="üìñ", layout="wide")

# Initialize session state
if 'read_articles' not in st.session_state:
    st.session_state.read_articles = set()
if 'reading_history' not in st.session_state:
    st.session_state.reading_history = []  # List to store all read articles
if 'current_view' not in st.session_state:
    st.session_state.current_view = "main"  # "main" or "detail"
if 'current_article_id' not in st.session_state:
    st.session_state.current_article_id = None
if 'selected_topic' not in st.session_state:
    st.session_state.selected_topic = "D√†nh cho b·∫°n (T·∫•t c·∫£)"
if 'selected_sources' not in st.session_state:
    st.session_state.selected_sources = []

@st.cache_resource
def get_sbert_model():
    return SentenceTransformer('Cloyne/vietnamese-sbert-v3')

def local_css(file_name):
    try:
        with open(file_name, "r", encoding="utf-8") as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    except FileNotFoundError:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file '{file_name}'.")

# --- H√ÄM T·∫¢I D·ªÆ LI·ªÜU ---
@st.cache_data
def load_data_and_embeddings():
    df = pd.read_csv('final_articles_for_app.csv')
    cosine_sim = np.load('cosine_similarity_matrix.npy')
    with open('topic_labels.json', 'r', encoding='utf-8') as f:
        topic_labels = json.load(f)
    df['published_time'] = pd.to_datetime(df['published_time'])
    df['source_name'] = df['link'].apply(get_source_name)
    # Lu√¥n y√™u c·∫ßu embeddings.npy ph·∫£i t·ªìn t·∫°i
    try:
        embeddings = np.load('embeddings.npy')
    except:
        st.error("Kh√¥ng t√¨m th·∫•y file embeddings.npy. Vui l√≤ng ch·∫°y l·∫°i pipeline ƒë·ªÉ t·∫°o embeddings.")
        st.stop()
    return df, cosine_sim, topic_labels, embeddings

def get_source_name(link):
    try:
        domain = urlparse(link).netloc
        if domain.startswith('www.'): domain = domain[4:]
        return domain.split('.')[0].capitalize()
    except:
        return "N/A"

# --- C√ÅC H√ÄM HI·ªÇN TH·ªä (RENDER) ---
def render_main_grid(df, selected_topic_name):
    st.header(f"B·∫£ng tin: {selected_topic_name}")
    st.markdown(f"T√¨m th·∫•y **{len(df)}** b√†i vi·∫øt li√™n quan.")
    st.markdown("---")
    num_columns = 3
    cols = st.columns(num_columns)
    if df.empty:
        st.warning("Kh√¥ng c√≥ b√†i vi·∫øt n√†o ph√π h·ª£p v·ªõi l·ª±a ch·ªçn c·ªßa b·∫°n.")
    else:
        for i, (index, row) in enumerate(df.iterrows()):
            with cols[i % num_columns]:
                # X·ª≠ l√Ω h√¨nh ·∫£nh v·ªõi placeholder
                image_html = ''
                if pd.notna(row["image_url"]):
                    image_html = f'<div class="card-image-container"><img src="{row["image_url"]}" onerror="this.onerror=null; this.src=\'no-image-png-2.webp\';"></div>'
                else:
                    image_html = '<div class="card-image-container"><img src="no-image-png-2.webp"></div>'
                
                # S·ª≠ d·ª•ng c·ªôt 'source_name' ƒë√£ t·∫°o
                source_name = row['source_name']


                card_html = f"""<div class="article-card">
                                {image_html}
                                <div class="article-content">
                                    <div class="article-title">{row['title']}</div>
                                    <div class="article-source">{source_name}</div>
                                </div>
                           </div>"""
                st.markdown(card_html, unsafe_allow_html=True)
                if st.button("ƒê·ªçc b√†i vi·∫øt", key=f"read_{index}"):
                    st.session_state.current_article_id = index
                    st.session_state.current_view = "detail"
                    st.rerun()

                

def calculate_interest_vector(df, cosine_sim, article_ids):
    """Calculate interest vector from reading history."""
    if not article_ids:
        return None
    
    # Get vectors for articles in history
    vectors = []
    for article_id in article_ids:
        if article_id < len(cosine_sim):
            vectors.append(cosine_sim[article_id])
    
    if not vectors:
        return None
    
    # Calculate average vector
    avg_vector = np.mean(vectors, axis=0)
    return avg_vector

def update_interest_vector(df, cosine_sim, article_id):
    """Update interest vector when new article is read."""
    if article_id not in st.session_state.reading_history:
        # Add to reading history (keep last 5)
        st.session_state.reading_history.insert(0, article_id)
        st.session_state.reading_history = st.session_state.reading_history[:5]
        
        # Calculate new interest vector
        st.session_state.interest_vector = calculate_interest_vector(
            df, cosine_sim, st.session_state.reading_history
        )
        
        # Update interest articles if vector exists
        if st.session_state.interest_vector is not None:
            similarity_scores = cosine_similarity([st.session_state.interest_vector], cosine_sim)[0]
            # Create mask to exclude read articles
            mask = ~df.index.isin(st.session_state.reading_history)
            similarity_scores[~mask] = -1  # Set similarity to -1 for read articles
            # Get top similar articles
            top_indices = np.argsort(similarity_scores)[::-1][:10]
            st.session_state.interest_articles = df.iloc[top_indices].copy()
            st.session_state.interest_articles['similarity_score'] = similarity_scores[top_indices]

def get_interest_articles():
    """Get articles based on user's interests."""
    if st.session_state.interest_articles is not None:
        return st.session_state.interest_articles
    return pd.DataFrame()

def calculate_average_vector(article_ids, cosine_sim):
    """Calculate average vector from last 5 articles."""
    if not article_ids:
        return None
    
    vectors = []
    for article_id in article_ids:
        if article_id < len(cosine_sim):
            vectors.append(cosine_sim[article_id])
    
    if not vectors:
        return None
    
    return np.mean(vectors, axis=0)

def get_similar_articles_by_history(df, cosine_sim, history_articles, exclude_articles=None):
    """Get similar articles based on reading history."""
    if not history_articles:
        return pd.DataFrame()
    
    # Ch·ªâ l·∫•y 5 b√†i vi·∫øt m·ªõi ƒë·ªçc g·∫ßn nh·∫•t
    recent_articles = history_articles[:5]
    
    avg_vector = calculate_average_vector(recent_articles, cosine_sim)
    if avg_vector is None:
        return pd.DataFrame()
    
    # Calculate similarity scores
    similarity_scores = cosine_similarity([avg_vector], cosine_sim)[0]
    
    # Create mask to exclude read articles
    if exclude_articles:
        mask = ~df.index.isin(exclude_articles)
        similarity_scores[~mask] = -1
    
    # Get top similar articles
    top_indices = np.argsort(similarity_scores)[::-1][:10]
    similar_articles = df.iloc[top_indices].copy()
    similar_articles['similarity_score'] = similarity_scores[top_indices]
    
    return similar_articles

def render_detail_view(article_id, df, cosine_sim, topic_labels):
    try:
        article = df.loc[article_id]
    except KeyError:
        st.error("Kh√¥ng t√¨m th·∫•y b√†i vi·∫øt.")
        if st.button("‚¨ÖÔ∏è Quay l·∫°i danh s√°ch"):
            st.session_state.current_view = "main"
            st.session_state.current_article_id = None
            st.rerun()
        return
    
    # Add article to read articles set and update reading history
    st.session_state.read_articles.add(article_id)
    if article_id not in st.session_state.reading_history:
        st.session_state.reading_history.insert(0, article_id)  # Add to history without limit
    
    if st.button("‚¨ÖÔ∏è Quay l·∫°i danh s√°ch"):
        st.session_state.current_view = "main"
        st.session_state.current_article_id = None
        st.rerun()
    
    st.title(article['title'])
    vn_time = article['published_time'].tz_convert('Asia/Ho_Chi_Minh')
    st.caption(f"Ngu·ªìn: {article['source_name']} | Xu·∫•t b·∫£n: {vn_time.strftime('%d-%m-%Y %H:%M')}")
    st.markdown("---")
    col1, col2 = st.columns([0.6, 0.4])
    with col1:
        if pd.notna(article['image_url']):
            st.markdown(f'<img src="{article["image_url"]}" onerror="this.onerror=null; this.src=\'no-image-png-2.webp\';" style="width:100%;">', unsafe_allow_html=True)
        else:
            st.markdown('<img src="no-image-png-2.webp" style="width:100%;">', unsafe_allow_html=True)
        st.subheader("T√≥m t·∫Øt")
        summary_raw = article.get('summary_raw', '')
        summary_without_img = re.sub(r'<img[^>]*>', '', summary_raw, flags=re.IGNORECASE)
        st.markdown(summary_without_img, unsafe_allow_html=True)
        st.link_button("ƒê·ªçc to√†n b·ªô b√†i vi·∫øt tr√™n trang g·ªëc", article['link'])
    with col2:
        st.subheader("Kh√°m ph√° th√™m")
        rec_type = st.radio("Hi·ªÉn th·ªã c√°c b√†i vi·∫øt:", ("C√≥ n·ªôi dung t∆∞∆°ng t·ª±", "Trong c√πng ch·ªß ƒë·ªÅ"), key=f"rec_type_{article_id}")
        
        if rec_type == "C√≥ n·ªôi dung t∆∞∆°ng t·ª±":
            st.markdown("##### D·ª±a tr√™n ph√¢n t√≠ch ng·ªØ nghƒ©a:")
            sim_scores = sorted(list(enumerate(cosine_sim[article_id])), key=lambda x: x[1], reverse=True)[1:6]
            for i, (article_index, score) in enumerate(sim_scores):
                rec_article = df.iloc[article_index]
                with st.container(border=True):
                    rec_col1, rec_col2 = st.columns([0.25, 0.75])
                    with rec_col1:
                        if pd.notna(rec_article['image_url']):
                            st.markdown(f'<img src="{rec_article["image_url"]}" onerror="this.onerror=null; this.src=\'no-image-png-2.webp\';" style="width:100%;">', unsafe_allow_html=True)
                        else:
                            st.markdown('<img src="no-image-png-2.webp" style="width:100%;">', unsafe_allow_html=True)
                    with rec_col2:
                        if st.button(rec_article['title'], key=f"rec_{article_index}"):
                            st.session_state.current_article_id = article_index
                            st.rerun()
                        st.caption(f"Ngu·ªìn: {rec_article['source_name']} | ƒê·ªô t∆∞∆°ng ƒë·ªìng: {score:.2f}")
        else: # C√πng ch·ªß ƒë·ªÅ
            cluster_id = article['topic_cluster']
            topic_name = topic_labels.get(str(cluster_id), "N/A")
            st.markdown(f"##### Thu·ªôc ch·ªß ƒë·ªÅ: **{topic_name}**")
            same_cluster_df = df[(df['topic_cluster'] == cluster_id) & (df.index != article_id)].head(5)
            for i, row in same_cluster_df.iterrows():
                with st.container(border=True):
                    rec_col1, rec_col2 = st.columns([0.25, 0.75])
                    with rec_col1:
                        if pd.notna(row['image_url']):
                            st.markdown(f'<img src="{row["image_url"]}" onerror="this.onerror=null; this.src=\'no-image-png-2.webp\';" style="width:100%;">', unsafe_allow_html=True)
                        else:
                            st.markdown('<img src="no-image-png-2.webp" style="width:100%;">', unsafe_allow_html=True)
                    with rec_col2:
                        if st.button(row['title'], key=f"rec_{i}"):
                            st.session_state.current_article_id = i
                            st.rerun()
                        # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cho b√†i vi·∫øt c√πng ch·ªß ƒë·ªÅ
                        similarity_score = cosine_sim[article_id][i]
                        st.caption(f"Ngu·ªìn: {row['source_name']} | ƒê·ªô t∆∞∆°ng ƒë·ªìng: {similarity_score:.2f}")

def render_search_results(query, df, embeddings, sbert_model):
    """Vector h√≥a truy v·∫•n v√† hi·ªÉn th·ªã k·∫øt qu·∫£ t√¨m ki·∫øm."""
    st.header(f"K·∫øt qu·∫£ t√¨m ki·∫øm cho: \"{query}\"")
    # Vector h√≥a c√¢u truy v·∫•n
    with st.spinner("ƒêang ph√¢n t√≠ch v√† t√¨m ki·∫øm..."):
        query_vector = sbert_model.encode([query])
        # T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng
        similarities = cosine_similarity(query_vector, embeddings)[0]
        # S·∫Øp x·∫øp v√† l·∫•y k·∫øt qu·∫£
        sim_scores = sorted(list(enumerate(similarities)), key=lambda x: x[1], reverse=True)
        result_indices = [i[0] for i in sim_scores]
        result_df = df.iloc[result_indices].copy()
    render_main_grid(result_df, f"K·∫øt qu·∫£ cho: \"{query}\"")

# --- LU·ªíNG CH√çNH C·ª¶A ·ª®NG D·ª§NG ---
local_css("style.css")

# --- PH·∫¶N LOGIC M·ªöI: QU·∫¢N L√ù TR·∫†NG TH√ÅI ---
if 'update_log' not in st.session_state:
    st.session_state.update_log = ""
if 'update_error' not in st.session_state:
    st.session_state.update_error = ""
if 'update_success' not in st.session_state:
    st.session_state.update_success = False

# Initialize session state for reading history and interest tracking
if 'reading_history' not in st.session_state:
    st.session_state.reading_history = []
if 'interest_vector' not in st.session_state:
    st.session_state.interest_vector = None
if 'interest_articles' not in st.session_state:
    st.session_state.interest_articles = None

df, cosine_sim, topic_labels, embeddings = load_data_and_embeddings()
sbert_model = get_sbert_model()

# --- √î T√åM KI·∫æM SEMANTIC ·ªû HEADER ---
search_col1, search_col2 = st.columns([0.85, 0.15])
with search_col1:
    search_input = st.text_input(
        "T√¨m ki·∫øm b√†i vi·∫øt (theo ng·ªØ nghƒ©a, nh·∫≠p t·ª´ kh√≥a ho·∫∑c c√¢u h·ªèi):",
        value=st.session_state.get('search_query', ''),
        key="search_input",
        placeholder="Nh·∫≠p n·ªôi dung b·∫°n mu·ªën t√¨m...",
        label_visibility="collapsed"
    )
with search_col2:
    search_button = st.button("üîç T√¨m ki·∫øm", use_container_width=True)

if search_input and (search_button or search_input != st.session_state.get('search_query', '')):
    st.session_state['search_query'] = search_input
    st.session_state['current_view'] = "search"
    st.rerun()

if st.session_state.get('current_view', 'main') == "search" and st.session_state.get('search_query', ''):
    with st.spinner("ƒêang ph√¢n t√≠ch v√† t√¨m ki·∫øm..."):
        query_vector = sbert_model.encode([st.session_state['search_query']])
        similarities = cosine_similarity(query_vector, embeddings)[0]
        sim_scores = sorted(list(enumerate(similarities)), key=lambda x: x[1], reverse=True)
        result_indices = [i[0] for i in sim_scores]
        result_df = df.iloc[result_indices].copy()
    st.sidebar.info("B·∫°n ƒëang ·ªü trang k·∫øt qu·∫£ t√¨m ki·∫øm. Ch·ªçn danh m·ª•c kh√°c ho·∫∑c b·∫•m 'Quay l·∫°i' ƒë·ªÉ tr·ªü v·ªÅ.")
    if st.sidebar.button("‚¨ÖÔ∏è Quay l·∫°i trang ch·ªß", use_container_width=True):
        st.session_state['search_query'] = ''
        st.session_state['current_view'] = "main"
        st.rerun()
    render_main_grid(result_df, f"K·∫øt qu·∫£ cho: \"{st.session_state['search_query']}\"")
    st.stop()
elif st.session_state.current_view == "detail" and st.session_state.current_article_id is not None:
    render_detail_view(st.session_state.current_article_id, df, cosine_sim, topic_labels)
else:
    # --- GIAO DI·ªÜN THANH B√äN ---
    st.sidebar.title("T·∫°p ch√≠ c·ªßa b·∫°n")
    st.sidebar.markdown("---")

    # N√∫t c·∫≠p nh·∫≠t
    if st.sidebar.button("üîÑ C·∫≠p nh·∫≠t tin t·ª©c m·ªõi", use_container_width=True):
        with st.spinner("‚è≥ ƒêang ch·∫°y pipeline... Vi·ªác n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t."):
            try:
                process = subprocess.run(
                    [sys.executable, 'pipeline.py'], capture_output=True, text=True,
                    encoding='utf-8', errors='ignore'
                )
                st.session_state.update_log = process.stdout
                st.session_state.update_error = process.stderr
                st.session_state.update_success = True
                st.cache_data.clear() # X√≥a cache ƒë·ªÉ chu·∫©n b·ªã t·∫£i l·∫°i
            except Exception as e:
                st.session_state.update_error = f"L·ªói nghi√™m tr·ªçng khi ch·∫°y pipeline: {e}"
                st.session_state.update_success = False

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ c·∫≠p nh·∫≠t v√† n√∫t t·∫£i l·∫°i
    if st.session_state.update_success:
        st.sidebar.success("‚úÖ C·∫≠p nh·∫≠t ho√†n t·∫•t!")
        with st.sidebar.expander("Xem chi ti·∫øt qu√° tr√¨nh"):
            st.code(st.session_state.update_log)
            if st.session_state.update_error:
                st.error("L·ªói t·ª´ pipeline:")
                st.code(st.session_state.update_error)
        if st.sidebar.button("Xem tin t·ª©c m·ªõi", use_container_width=True):
            st.session_state.update_success = False # Reset c·ªù
            st.rerun()

    st.sidebar.markdown("---")

    if df is None:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu. Vui l√≤ng b·∫•m n√∫t 'C·∫≠p nh·∫≠t tin t·ª©c m·ªõi' ·ªü thanh b√™n.")
    else:
        # --- PH·∫¶N L·ªåC THEO CH·ª¶ ƒê·ªÄ ---
        st.sidebar.subheader("Kh√°m ph√° c√°c ch·ªß ƒë·ªÅ")
        topic_display_list = ["D√†nh cho b·∫°n (T·∫•t c·∫£)", "B√†i vi·∫øt ƒë√£ ƒë·ªçc", "D·ª±a tr√™n l·ªãch s·ª≠ ƒë·ªçc"] + [v for k, v in topic_labels.items()]
        
        st.sidebar.markdown('<div class="sidebar-nav">', unsafe_allow_html=True)
        for topic in topic_display_list:
            is_active = (topic == st.session_state.selected_topic)
            active_class = "active" if is_active else ""
            icon = "üìñ" if topic != "B√†i vi·∫øt ƒë√£ ƒë·ªçc" and topic != "D·ª±a tr√™n l·ªãch s·ª≠ ƒë·ªçc" else "üëÅÔ∏è" if topic == "B√†i vi·∫øt ƒë√£ ƒë·ªçc" else "üéØ"
            if st.sidebar.button(f"{icon} {topic}", key=f"topic_{topic}", use_container_width=True):
                st.session_state.selected_topic = topic
                st.rerun()
        st.sidebar.markdown('</div>', unsafe_allow_html=True)
        st.sidebar.markdown("---")

        # --- B·ªî SUNG: PH·∫¶N L·ªåC THEO NGU·ªíN ---
        st.sidebar.subheader("L·ªçc theo ngu·ªìn")
        all_sources = sorted(df['source_name'].unique().tolist())
        selected_sources = st.sidebar.multiselect(
            "Ch·ªçn m·ªôt ho·∫∑c nhi·ªÅu ngu·ªìn:",
            options=all_sources,
            default=st.session_state.selected_sources
        )
        
        if selected_sources != st.session_state.selected_sources:
            st.session_state.selected_sources = selected_sources
            st.rerun()

        # --- HI·ªÇN TH·ªä VIEW T∆Ø∆†NG ·ª®NG ---
        if st.session_state.selected_topic == "B√†i vi·∫øt ƒë√£ ƒë·ªçc":
            if st.session_state.read_articles:
                # L·∫•y danh s√°ch b√†i vi·∫øt ƒë√£ ƒë·ªçc theo th·ª© t·ª± trong reading_history (m·ªõi nh·∫•t l√™n ƒë·∫ßu)
                ordered_articles = [article_id for article_id in st.session_state.reading_history if article_id in st.session_state.read_articles]
                # T·∫°o DataFrame v·ªõi th·ª© t·ª± ƒë√£ s·∫Øp x·∫øp
                display_df = df[df.index.isin(ordered_articles)].copy()
                # S·∫Øp x·∫øp l·∫°i theo th·ª© t·ª± trong ordered_articles
                display_df = display_df.reindex(ordered_articles)
            else:
                display_df = pd.DataFrame()
                st.info("B·∫°n ch∆∞a ƒë·ªçc b√†i vi·∫øt n√†o.")
        elif st.session_state.selected_topic == "D·ª±a tr√™n l·ªãch s·ª≠ ƒë·ªçc":
            if len(st.session_state.reading_history) > 0:
                display_df = get_similar_articles_by_history(
                    df, cosine_sim,
                    st.session_state.reading_history,
                    exclude_articles=st.session_state.read_articles
                )
                if display_df.empty:
                    st.info("Kh√¥ng t√¨m th·∫•y b√†i vi·∫øt t∆∞∆°ng t·ª± d·ª±a tr√™n l·ªãch s·ª≠ ƒë·ªçc.")
            else:
                display_df = pd.DataFrame()
                st.info("B·∫°n ch∆∞a c√≥ l·ªãch s·ª≠ ƒë·ªçc b√†i vi·∫øt n√†o.")
        elif st.session_state.selected_topic != "D√†nh cho b·∫°n (T·∫•t c·∫£)":
            selected_key_list = [k for k, v in topic_labels.items() if v == st.session_state.selected_topic]
            if selected_key_list:
                display_df = df[df['topic_cluster'] == int(selected_key_list[0])].copy()
            else:
                display_df = pd.DataFrame()
        else:
            display_df = df.copy()

        # √Åp d·ª•ng b·ªô l·ªçc ngu·ªìn
        if st.session_state.selected_sources:
            display_df = display_df[display_df['source_name'].isin(st.session_state.selected_sources)]

        # S·∫Øp x·∫øp v√† hi·ªÉn th·ªã
        if not display_df.empty:
            # Ch·ªâ s·∫Øp x·∫øp theo th·ªùi gian ƒëƒÉng n·∫øu kh√¥ng ph·∫£i l√† b√†i vi·∫øt ƒë√£ ƒë·ªçc
            if st.session_state.selected_topic != "B√†i vi·∫øt ƒë√£ ƒë·ªçc":
                display_df = display_df.sort_values(by='published_time', ascending=False)
        render_main_grid(display_df, st.session_state.selected_topic)
